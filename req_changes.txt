Below I (1) explain the likely root causes, then (2) give exact code patches / snippets to apply in three places (`global_search`/Monte Carlo behavior, `hybrid` local-refinement logic, and `calculate_vs30`), and (3) propose a quick checklist to run after applying patches.

---

# 1) Likely root causes (diagnostic summary)

Based on the repo structure you showed and common MASW pitfalls, the uniform 37.33 m layer and identical Vs10/Vs15/Vs20/Vs30 almost always come from one (or more) of the following:

* **Layer parameterization / model merging**: the inversion parameterization or initial model may include a single shallow layer whose thickness ≥ 30 m. If the best-fit model places >30 m in first layer, time-averaged Vs10-30 = Vs of layer1.
* **No smoothing or penalization of unrealistic layer thicknesses**: unconstrained inversion can place a very thick shallow layer if that reduces the dispersion-misfit metric, especially when inversion cost is dominated by certain frequency bands.
* **Hybrid refinement always overwrites the Monte Carlo best model** even when local LM refinement increases RMS; i.e., hybrid.py likely takes a Monte Carlo seed, refines with least-squares, and **unconditionally** writes out the refined model as "final" instead of keeping the model with the lowest RMS. That would explain why the Monte Carlo *best* RMS is 37.80 m/s, but the reported Hybrid RMS is 77.62 m/s (worse) and still chosen as final.
* **Inconsistent vs30 rounding/reporting**: Vs30 computed in `calculate_vs30.py` may return a float, while elsewhere code prints a rounded value; different rounding/formatting calls produce 287.5 / 287.6 / 288 in different places.

---

# 2) Concrete fixes (copy-paste ready).

Below are minimal, safe edits you can make. They are small guards and formatting fixes — they do **not** overhaul your inversion strategy but will stop the pathological behaviors and make outputs consistent.

## A — Hybrid refinement: only accept local refinement if misfit improves

Edit `code/inversion/hybrid.py` so that after running local least-squares refinement on the Monte Carlo candidate, the code **compares RMS before and after** and keeps the better model.

Replace the refinement section with something like the snippet below (search for where the code calls the least-squares routine on a Monte Carlo model and writes the hybrid result):

```python
# --- hybrid.py: protect against worse local refinement ---
# PSEUDOCODE/INSERT: adapt names to your existing function names
# assume `mc_model` is the model coming from Monte Carlo,
# `compute_rms(model)` returns RMS misfit,
# and `least_squares_refine(model)` returns (refined_model, refined_rms)

seed_model = mc_model.copy()
seed_rms = compute_rms(seed_model)

# run local refinement
refined_model, refined_rms = least_squares_refine(seed_model)

# Accept refinement only if it improves RMS (or is within a tiny tolerance)
improvement_tol = 1e-6  # small tolerance
if refined_rms + improvement_tol < seed_rms:
    final_candidate = refined_model
    final_rms = refined_rms
    accepted = "refined"
else:
    final_candidate = seed_model
    final_rms = seed_rms
    accepted = "seed"

# log what was kept
logger.info(f"Hybrid candidate accepted: {accepted} (seed_rms={seed_rms:.3f}, refined_rms={refined_rms:.3f})")

# Save or append `final_candidate` and `final_rms` to hybrid results instead of always using refined_model
```

**Rationale:** this prevents the hybrid routine from producing a worse model than the Monte Carlo result and being unconditionally saved as final.

---

## B — Run/inversion orchestration: pick the model with the lowest RMS for final reporting

Edit `code/inversion/run_inversion.py` (the top-level script that coordinates methods) so that final selection is explicitly the model with the minimum RMS among all tested approaches (Monte Carlo best, least-squares final, and hybrid final). Example snippet:

```python
# --- run_inversion.py: pick minimum-RMS model for final output ---
# assume you collect outputs as dicts:
# results = {
#   "least_squares": {"model": ls_model, "rms": ls_rms},
#   "monte_carlo_best": {"model": mc_best_model, "rms": mc_best_rms},
#   "hybrid": {"model": hybrid_model, "rms": hybrid_rms},
# }

# gather rms values
rms_items = [(k, v["rms"]) for k, v in results.items()]
best_method, best_rms = min(rms_items, key=lambda x: x[1])
best_model = results[best_method]["model"]

print(f"Selected final model: {best_method} with RMS = {best_rms:.4f}")
# Then use best_model for Vs30, plotting, and report outputs
save_model(best_model, outpath="data/vs_profile_final.txt")
```

**Rationale:** this enforces your stated policy ("We will be taking the final value from the model which gives least error") and avoids contradictory report statements.

---

## C — Monte Carlo / global search: constrain parameter ranges / prevent huge shallow layers

In `code/inversion/global_search.py` add reasonable parameter **bounds** on layer thickness and Vs ranges, and (optionally) penalize single-layer-dominant solutions. Two practical measures:

1. **Set upper bound on first-layer thickness** to something slightly greater than 30 m if you want to allow a thick top layer but avoid it being unphysically huge — for example, `max_first_layer_thickness = 40.0` m. Or better: do not allow the first layer thickness to exceed 0.6 × max_model_depth (or a fixed value like 40 m).

2. **Add a penalty term** to the Monte Carlo scoring function that pushes against models with an extremely large fraction of the total 30 m in a single layer. Example:

```python
# inside the scoring function used by Monte Carlo:
rms = compute_rms(candidate_model)

# encourage geologically realistic layered solutions
# fraction_shallow = min(sum of h_i down to 30m) / 30.0 (how much of top 30m is from layer1)
frac_from_first_layer = compute_fraction_top30_from_first_layer(candidate_model)
penalty = 0.0
if frac_from_first_layer > 0.9:
    # mild penalty for >90% of the top 30m being a single layer
    penalty = 0.1 * rms  # or an absolute penalty
score = rms * (1.0 + penalty)

# Use `score` for selection/acceptance instead of raw rms
```

Or simply **reject** models where the first layer thickness ≥ 30 m (if you want to enforce multi-layer top30). Choose penalty/rejection based on how strict you want geological realism to be.

**Rationale:** this lessens the chance Monte Carlo will find a lower RMS by collapsing the 30 m interval into a single layer.

---

## D — Fix Vs30 calculation and consistent rounding

Open `code/vs30/calculate_vs30.py` and ensure:

* Vs30 calculation always uses the **same** function (single source of truth).
* The function returns a float but file writing and printed numbers use a single formatting rule (e.g., one decimal place).
* Use consistent rounding only at print/save time — keep full precision internally.

Suggested replacement of function stub / final formatting:

```python
# calculate_vs30.py

def compute_vs_time_average(model_layers, depth=30.0):
    """
    model_layers: list of (h, Vs) tuples, h in meters. Last layer can be infinite (use None or np.inf).
    Returns float Vs30 (time-averaged to `depth`).
    """
    remaining = depth
    numerator = 0.0
    for h, Vs in model_layers:
        if h is None or np.isinf(h):
            h_eff = remaining
        else:
            h_eff = min(h, remaining)
        numerator += h_eff / Vs
        remaining -= h_eff
        if remaining <= 1e-8:
            break
    if remaining > 1e-6:
        # depth not covered — raise or extrapolate from last Vs
        last_vs = model_layers[-1][1]
        numerator += remaining / last_vs
    Vs30 = depth / numerator
    return Vs30

# When printing / saving:
vs30_val = compute_vs_time_average(layers)
vs30_report = round(vs30_val, 1)  # e.g., 287.5 -> 287.5 ; this ensures consistent decimals
print(f"Vs30 = {vs30_report:.1f} m/s")
# write vs30_report to any summary files so the same printed value appears everywhere
```

**Rationale:** Ensures numbers like 287.5 / 287.6 / 288 do not come from inconsistent rounding at three different points in the code.

---

# 3) Small additional quality-of-life improvements (recommended)

* Add a short log entry when saving the final model that includes which method was chosen and its RMS. This prevents contradictory statements in the report.
* When you save `vs_profile_final.txt` and `inversion_summary.txt` ensure they read from the same `best_model` and same Vs30 variable. (E.g., call `compute_vs_time_average(best_model.layers)` and use that value for both files.)
* Add a unit test (small) to assert that if the top-layer thickness > 30 m, then Vs10/Vs15/Vs20/Vs30 will all equal top-layer Vs — and flag this as "expected but suspicious" so users know it's an artifact vs. expected geological result.

---

# 4) Quick post-patch checklist to run locally

1. Apply the three edits above (hybrid.py guard, run_inversion final selection, calculate_vs30 rounding).
2. Run `python code/inversion/run_inversion.py` (or your usual command) on the same dispersion input.
3. Check printed output: which method is chosen and its RMS — verify it is the lowest RMS.
4. Check `data/vs_profile_final.txt` / `inversion_summary.txt` and confirm Vs30 matches the printed value exactly.
5. Plot Vs profile and inspect top 30 m: if it still is a single-layer dominating top30, either relax penalty or inspect the dispersion weighting (sometimes weighting on low frequencies encourages large shallow layer). Consider adding regularization or additional frequency weighting if needed.

---
